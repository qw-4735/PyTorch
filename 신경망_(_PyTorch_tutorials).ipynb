{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "신경망 ( PyTorch tutorials).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTqrGGw/YxCDThgve9Lvv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qw-4735/PyTorch/blob/main/%EC%8B%A0%EA%B2%BD%EB%A7%9D_(_PyTorch_tutorials).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 신경망(Neural Networks)\n",
        "- 신경망은 torch.nn 패키지를 사용하여 생성\n",
        "- nn 은 모델을 정의하고 미분하는데 autograd를 사용\n",
        "- nn.Module은 계층(layer)과 output을 반환하는 forward 메서드를 포함"
      ],
      "metadata": {
        "id": "cDbbH_it0yQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn은 미니배치만 지원한다.\n",
        " \n",
        "즉, torch.nn 패키지 전체는 하나의 샘플이 아닌, 샘플들의 미니배치만을 입력으로 받는다."
      ],
      "metadata": {
        "id": "RJK0BZNP_Y6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ox-zLSp8v4FA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # 컨볼루션 커널 정의\n",
        "    self.conv1 = nn.Conv2d(1,6,5)  # 입력 이미지 채널 1개, 출력채널 6개, 5x5 정사각 컨볼루션 행렬\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    \n",
        "    self.fc1 = nn.Linear(16*5*5 ,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))    # (2,2) 크기 윈도우에 대해 max pooling\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)),2)        # 크기가 제곱수라면, 하나의 숫자만을 특정\n",
        "    x = torch.flatten(x,1)    # 배치 차원을 제외한 모든 차원을 하나로 flatten\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x) \n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "print(net)     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH3M5A63wuYt",
        "outputId": "9ff7d29f-50b9-44f0-d728-b7c17253db72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "forward 함수만 정의하고 나면, (변화도를 계산하는) backward 함수는 autograd를 사용하여 자동으로 정의된다."
      ],
      "metadata": {
        "id": "CCybIu2l-JvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 학습 가능한 매개변수들은 net.parameters()에 의해 반환됨\n",
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())   # conv1의 weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aKD-xG29gtU",
        "outputId": "934c2574-854f-4709-c7a7-147baf26bd86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "torch.Size([6, 1, 5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 32 x 32 입력값을 넣어보자\n",
        "input = torch.randn(1,1,32,32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_I45Ntl-ly7",
        "outputId": "112c4429-f54d-4cad-9121-1321d1a04467"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0886,  0.0885,  0.0524,  0.0623,  0.0221,  0.0443, -0.1012,  0.0451,\n",
            "          0.0299,  0.0222]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 매개변수의 변화도 버퍼(gradient buffer)를 0으로 설정하고, 무작위 값으로 역전파\n",
        "net.zero_grad()\n",
        "out.backward(torch.randn(1,10))"
      ],
      "metadata": {
        "id": "bwpmcBZu_CbK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 손실함수 (Loss Function)\n",
        "- 손실함수는 (output, target)을 한 쌍(pair)의 입력으로 받아, 출력(output)이 정답(target)으로부터 얼마나 멀리 떨어져있는지 추정하는 값을 계산\n",
        "- nn 패키지에는 여러가지 손실함수들이 존재 ex) nn.MSEloss"
      ],
      "metadata": {
        "id": "cRelhj5hAESY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)  # 예시를 위한 임의의 정답\n",
        "target = target.view(1,-1)   # 출력과 같은 shape를 만듦\n",
        "criterion = nn.MSELoss  \n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "0NBy1e_v_Vyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 역전파의 몇 과정 예시\n",
        "print(loss.grad_fn)    # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])   # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])   # ReLU"
      ],
      "metadata": {
        "id": "gcylzBHiA_P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 역전파\n",
        "오차를 역전파하기 위해서는 loss.backward()만 해주면 된다.\n",
        "\n",
        "기존에 계산된 변화도의 값을 누적시키고 싶지 ㅇㄶ다면, 기존에 계산된 변화도를 0으로 만드는 작업이 필요"
      ],
      "metadata": {
        "id": "5OOBqaCECeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.zero_grad()   # 모든 매개변수의 변화도 버퍼를 0으로 만듦\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)    # loss.backward()를 호출하여 역전파 후의 conv1의 bias변수의 변화도를 살펴보자"
      ],
      "metadata": {
        "id": "oARatfx0Cbt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가중치 갱신\n",
        "new weight = weight - learning rate * gradient"
      ],
      "metadata": {
        "id": "EwQKe7SpFU8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "for f in net.parameters():\n",
        "  f.data.sub_(f.grad.data * learning_rate)"
      ],
      "metadata": {
        "id": "wnvzLve8E27f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# 학습 과정(training loop)은 다음과 같다:\n",
        "optimizer.zero_grad()   # 변화도 버퍼를 0으로\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()  # 업데이트 진행"
      ],
      "metadata": {
        "id": "p6HQ_Rd5Ft5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}